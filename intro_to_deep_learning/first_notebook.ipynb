{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "A = 5\n",
    "B = 8\n",
    "\n",
    "result = (2*A + 3*B )\n",
    "\n",
    "print(result)\n",
    "print(type(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 10 10 10 15 25]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "A = np.array([1,2,2,2,3,5])\n",
    "B = np.array([1,2,2,2,3,5])\n",
    "\n",
    "result = (2*A + 3*B )\n",
    "\n",
    "print(result)\n",
    "print(type(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 25 100 100 100 225 625], shape=(6,), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([1,2,2,2,3,5])\n",
    "B = tf.constant([1,2,2,2,3,5])\n",
    "\n",
    "result = (2*A + 3*B ) **2\n",
    "\n",
    "print(result)\n",
    "print(type(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = pd.read_csv('adult.csv', sep=',',engine='python' )\n",
    "income_data.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num','marital-status','occupation','relationship', 'race', 'sex', 'capital-gain', 'capital-loss','hours-per-week', 'native-country' , 'income_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt     education  education-num  \\\n",
       "0       25       Private  226802          11th              7   \n",
       "1       38       Private   89814       HS-grad              9   \n",
       "2       28     Local-gov  336951    Assoc-acdm             12   \n",
       "3       44       Private  160323  Some-college             10   \n",
       "4       18             ?  103497  Some-college             10   \n",
       "...    ...           ...     ...           ...            ...   \n",
       "48837   27       Private  257302    Assoc-acdm             12   \n",
       "48838   40       Private  154374       HS-grad              9   \n",
       "48839   58       Private  151910       HS-grad              9   \n",
       "48840   22       Private  201490       HS-grad              9   \n",
       "48841   52  Self-emp-inc  287927       HS-grad              9   \n",
       "\n",
       "           marital-status         occupation relationship   race     sex  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                  ?    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income_class  \n",
       "0                 0             0              40  United-States        <=50K  \n",
       "1                 0             0              50  United-States        <=50K  \n",
       "2                 0             0              40  United-States         >50K  \n",
       "3              7688             0              40  United-States         >50K  \n",
       "4                 0             0              30  United-States        <=50K  \n",
       "...             ...           ...             ...            ...          ...  \n",
       "48837             0             0              38  United-States        <=50K  \n",
       "48838             0             0              40  United-States         >50K  \n",
       "48839             0             0              40  United-States        <=50K  \n",
       "48840             0             0              20  United-States        <=50K  \n",
       "48841         15024             0              40  United-States         >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes = income_data.drop(columns = [\"income_class\"])\n",
    "income_target = income_data.income_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes = pd.get_dummies(income_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_target = income_target.replace({\"<=50K\":0 , \">50K\" : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes = income_attributes.drop(columns = ['fnlwgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37155\n",
       "1    11687\n",
       "Name: income_class, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes_train, income_attributes_test, income_target_train, income_target_test= train_test_split(\n",
    "    income_attributes,\n",
    "    income_target,\n",
    "    test_size= 5000,\n",
    "    random_state= 33,\n",
    "    stratify= income_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the stratificatons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.760709\n",
       "1    0.239291\n",
       "Name: income_class, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_target_train.value_counts()/ len(income_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7608\n",
       "1    0.2392\n",
       "Name: income_class, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_target_test.value_counts()/ len(income_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 10,  0, ...,  1,  0,  0],\n",
       "       [46, 13,  0, ...,  1,  0,  0],\n",
       "       [25, 11,  0, ...,  1,  0,  0],\n",
       "       ...,\n",
       "       [35, 10,  0, ...,  1,  0,  0],\n",
       "       [23, 10,  0, ...,  0,  0,  0],\n",
       "       [47,  9,  0, ...,  1,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_attributes_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "income_attributes_train_scaled = scaler.fit_transform(income_attributes_train)\n",
    "income_attributes_test_scaled = scaler.fit_transform(income_attributes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_attributes_train_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_atrributes = income_attributes.shape[1]\n",
    "num_atrributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regression = Sequential(\n",
    "    [\n",
    "        Input(shape = (num_atrributes,)),\n",
    "        Dense(1,activation = 'sigmoid')\n",
    "    ], name = 'log_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"log_reg\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 1)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regression.compile(loss = 'binary_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 275.4702\n",
      "Epoch 2/99\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 275.2953\n",
      "Epoch 3/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 275.1205\n",
      "Epoch 4/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 274.9456\n",
      "Epoch 5/99\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 274.7708\n",
      "Epoch 6/99\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 274.5959\n",
      "Epoch 7/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 274.4210\n",
      "Epoch 8/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 274.2462\n",
      "Epoch 9/99\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 274.0713\n",
      "Epoch 10/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 273.8965\n",
      "Epoch 11/99\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 273.7216\n",
      "Epoch 12/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 273.5468\n",
      "Epoch 13/99\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 273.3720\n",
      "Epoch 14/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 273.1972\n",
      "Epoch 15/99\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 273.0224\n",
      "Epoch 16/99\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 272.8476\n",
      "Epoch 17/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 272.6728\n",
      "Epoch 18/99\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 272.4980\n",
      "Epoch 19/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 272.3233\n",
      "Epoch 20/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 272.1485\n",
      "Epoch 21/99\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 271.9738\n",
      "Epoch 22/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 271.7990\n",
      "Epoch 23/99\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 271.6244\n",
      "Epoch 24/99\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 271.4496\n",
      "Epoch 25/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 271.2750\n",
      "Epoch 26/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 271.1003\n",
      "Epoch 27/99\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 270.9257\n",
      "Epoch 28/99\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 270.7511\n",
      "Epoch 29/99\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 270.5764\n",
      "Epoch 30/99\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 270.4019\n",
      "Epoch 31/99\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 270.2273\n",
      "Epoch 32/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 270.0528\n",
      "Epoch 33/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 269.8783\n",
      "Epoch 34/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 269.7039\n",
      "Epoch 35/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 269.5294\n",
      "Epoch 36/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 269.3551\n",
      "Epoch 37/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 269.1807\n",
      "Epoch 38/99\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 269.0064\n",
      "Epoch 39/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 268.8322\n",
      "Epoch 40/99\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 268.6580\n",
      "Epoch 41/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 268.4839\n",
      "Epoch 42/99\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 268.3098\n",
      "Epoch 43/99\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 268.1358\n",
      "Epoch 44/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 267.9619\n",
      "Epoch 45/99\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.7880\n",
      "Epoch 46/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 267.6142\n",
      "Epoch 47/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 267.4406\n",
      "Epoch 48/99\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 267.2670\n",
      "Epoch 49/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 267.0935\n",
      "Epoch 50/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 266.9202\n",
      "Epoch 51/99\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 266.7469\n",
      "Epoch 52/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 266.5738\n",
      "Epoch 53/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 266.4009\n",
      "Epoch 54/99\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 266.2281\n",
      "Epoch 55/99\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 266.0555\n",
      "Epoch 56/99\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 265.8830\n",
      "Epoch 57/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 265.7108\n",
      "Epoch 58/99\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 265.5388\n",
      "Epoch 59/99\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 265.3669\n",
      "Epoch 60/99\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 265.1954\n",
      "Epoch 61/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 265.0241\n",
      "Epoch 62/99\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 264.8530\n",
      "Epoch 63/99\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 264.6823\n",
      "Epoch 64/99\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 264.5119\n",
      "Epoch 65/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 264.3418\n",
      "Epoch 66/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 264.1720\n",
      "Epoch 67/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 264.0027\n",
      "Epoch 68/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 263.8337\n",
      "Epoch 69/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 263.6651\n",
      "Epoch 70/99\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 263.4969\n",
      "Epoch 71/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 263.3292\n",
      "Epoch 72/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 263.1620\n",
      "Epoch 73/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 262.9952\n",
      "Epoch 74/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 262.8289\n",
      "Epoch 75/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 262.6631\n",
      "Epoch 76/99\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 262.4979\n",
      "Epoch 77/99\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 262.3332\n",
      "Epoch 78/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 262.1689\n",
      "Epoch 79/99\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 262.0053\n",
      "Epoch 80/99\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 261.8421\n",
      "Epoch 81/99\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 261.6794\n",
      "Epoch 82/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 261.5172\n",
      "Epoch 83/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 261.3555\n",
      "Epoch 84/99\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 261.1943\n",
      "Epoch 85/99\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 261.0335\n",
      "Epoch 86/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 260.8731\n",
      "Epoch 87/99\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 260.7131\n",
      "Epoch 88/99\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 260.5535\n",
      "Epoch 89/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 260.3942\n",
      "Epoch 90/99\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 260.2351\n",
      "Epoch 91/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 260.0764\n",
      "Epoch 92/99\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 259.9178\n",
      "Epoch 93/99\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 259.7594\n",
      "Epoch 94/99\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 259.6012\n",
      "Epoch 95/99\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 259.4431\n",
      "Epoch 96/99\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 259.2850\n",
      "Epoch 97/99\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 259.1271\n",
      "Epoch 98/99\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 258.9692\n",
      "Epoch 99/99\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 258.8113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201c322a048>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regression.fit(\n",
    "    income_attributes_train,\n",
    "    income_target_train,\n",
    "    epochs = 99,\n",
    "    batch_size =len(income_attributes_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential([\n",
    "    Input(shape = (num_atrributes,)),\n",
    "    Dense(30,activation = 'relu'),\n",
    "    Dense(20,activation = 'relu'),\n",
    "    Dense(10,activation = 'relu'),\n",
    "    Dense(1,activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 30)                3240      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,081\n",
      "Trainable params: 4,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 161.6256 - accuracy: 0.7607\n",
      "Epoch 2/99\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 152.9873 - accuracy: 0.7607\n",
      "Epoch 3/99\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 144.4439 - accuracy: 0.7607\n",
      "Epoch 4/99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 137.2013 - accuracy: 0.7607\n",
      "Epoch 5/99\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 131.2139 - accuracy: 0.7607\n",
      "Epoch 6/99\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 125.0353 - accuracy: 0.7607\n",
      "Epoch 7/99\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 118.7835 - accuracy: 0.7607\n",
      "Epoch 8/99\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 112.5154 - accuracy: 0.7607\n",
      "Epoch 9/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 106.2634 - accuracy: 0.7607\n",
      "Epoch 10/99\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 100.0477 - accuracy: 0.7607\n",
      "Epoch 11/99\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 93.8818 - accuracy: 0.7607\n",
      "Epoch 12/99\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 87.7748 - accuracy: 0.7607\n",
      "Epoch 13/99\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 81.7677 - accuracy: 0.7607\n",
      "Epoch 14/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 76.0641 - accuracy: 0.7605\n",
      "Epoch 15/99\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 70.4345 - accuracy: 0.7604\n",
      "Epoch 16/99\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 64.8778 - accuracy: 0.7598\n",
      "Epoch 17/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 59.6861 - accuracy: 0.7600\n",
      "Epoch 18/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 54.8350 - accuracy: 0.7590\n",
      "Epoch 19/99\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 50.1664 - accuracy: 0.7577\n",
      "Epoch 20/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 45.5412 - accuracy: 0.7560\n",
      "Epoch 21/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 40.9438 - accuracy: 0.7550\n",
      "Epoch 22/99\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 36.3170 - accuracy: 0.7546\n",
      "Epoch 23/99\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 31.7621 - accuracy: 0.7546\n",
      "Epoch 24/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 27.1151 - accuracy: 0.7554\n",
      "Epoch 25/99\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 22.3811 - accuracy: 0.7564\n",
      "Epoch 26/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 17.6382 - accuracy: 0.7577\n",
      "Epoch 27/99\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 12.8975 - accuracy: 0.7589\n",
      "Epoch 28/99\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.1723 - accuracy: 0.7598\n",
      "Epoch 29/99\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.4740 - accuracy: 0.7604\n",
      "Epoch 30/99\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7272 - accuracy: 0.7823\n",
      "Epoch 31/99\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8403 - accuracy: 0.7795\n",
      "Epoch 32/99\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9429 - accuracy: 0.7797\n",
      "Epoch 33/99\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0042 - accuracy: 0.7798\n",
      "Epoch 34/99\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0072 - accuracy: 0.7798\n",
      "Epoch 35/99\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9716 - accuracy: 0.7799\n",
      "Epoch 36/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9067 - accuracy: 0.7799\n",
      "Epoch 37/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8180 - accuracy: 0.7797\n",
      "Epoch 38/99\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7105 - accuracy: 0.7796\n",
      "Epoch 39/99\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5975 - accuracy: 0.7788\n",
      "Epoch 40/99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5599 - accuracy: 0.7747\n",
      "Epoch 41/99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5877 - accuracy: 0.7797\n",
      "Epoch 42/99\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6150 - accuracy: 0.7822\n",
      "Epoch 43/99\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6353 - accuracy: 0.7812\n",
      "Epoch 44/99\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6343 - accuracy: 0.7811\n",
      "Epoch 45/99\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6126 - accuracy: 0.7813\n",
      "Epoch 46/99\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5757 - accuracy: 0.7823\n",
      "Epoch 47/99\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5433 - accuracy: 0.7827\n",
      "Epoch 48/99\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5843 - accuracy: 0.7616\n",
      "Epoch 49/99\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5734 - accuracy: 0.7802\n",
      "Epoch 50/99\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6177 - accuracy: 0.7797\n",
      "Epoch 51/99\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6408 - accuracy: 0.7796\n",
      "Epoch 52/99\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6415 - accuracy: 0.7794\n",
      "Epoch 53/99\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6263 - accuracy: 0.7783\n",
      "Epoch 54/99\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6100 - accuracy: 0.7829\n",
      "Epoch 55/99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6026 - accuracy: 0.7807\n",
      "Epoch 56/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5920 - accuracy: 0.7806\n",
      "Epoch 57/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5692 - accuracy: 0.7811\n",
      "Epoch 58/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5414 - accuracy: 0.7843\n",
      "Epoch 59/99\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6309 - accuracy: 0.7566\n",
      "Epoch 60/99\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5245 - accuracy: 0.7876\n",
      "Epoch 61/99\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5422 - accuracy: 0.7792\n",
      "Epoch 62/99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5615 - accuracy: 0.7791\n",
      "Epoch 63/99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5695 - accuracy: 0.7790\n",
      "Epoch 64/99\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - accuracy: 0.7786\n",
      "Epoch 65/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5532 - accuracy: 0.7807\n",
      "Epoch 66/99\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5402 - accuracy: 0.7852\n",
      "Epoch 67/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5282 - accuracy: 0.7840\n",
      "Epoch 68/99\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5214 - accuracy: 0.7865\n",
      "Epoch 69/99\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5605 - accuracy: 0.7629\n",
      "Epoch 70/99\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5196 - accuracy: 0.7868\n",
      "Epoch 71/99\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5366 - accuracy: 0.7849\n",
      "Epoch 72/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5529 - accuracy: 0.7807\n",
      "Epoch 73/99\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5625 - accuracy: 0.7788\n",
      "Epoch 74/99\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5628 - accuracy: 0.7790\n",
      "Epoch 75/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5542 - accuracy: 0.7803\n",
      "Epoch 76/99\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5399 - accuracy: 0.7838\n",
      "Epoch 77/99\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5236 - accuracy: 0.7869\n",
      "Epoch 78/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5100 - accuracy: 0.7896\n",
      "Epoch 79/99\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5152 - accuracy: 0.7828\n",
      "Epoch 80/99\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5610 - accuracy: 0.7622\n",
      "Epoch 81/99\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5103 - accuracy: 0.7898\n",
      "Epoch 82/99\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5366 - accuracy: 0.7847\n",
      "Epoch 83/99\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5599 - accuracy: 0.7819\n",
      "Epoch 84/99\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5747 - accuracy: 0.7809\n",
      "Epoch 85/99\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5799 - accuracy: 0.7810\n",
      "Epoch 86/99\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5763 - accuracy: 0.7822\n",
      "Epoch 87/99\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5652 - accuracy: 0.7838\n",
      "Epoch 88/99\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5480 - accuracy: 0.7854\n",
      "Epoch 89/99\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5263 - accuracy: 0.7867\n",
      "Epoch 90/99\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5046 - accuracy: 0.7904\n",
      "Epoch 91/99\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4972 - accuracy: 0.7921\n",
      "Epoch 92/99\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5466 - accuracy: 0.7609\n",
      "Epoch 93/99\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4945 - accuracy: 0.7923\n",
      "Epoch 94/99\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5096 - accuracy: 0.7880\n",
      "Epoch 95/99\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5269 - accuracy: 0.7859\n",
      "Epoch 96/99\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5378 - accuracy: 0.7851\n",
      "Epoch 97/99\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5409 - accuracy: 0.7849\n",
      "Epoch 98/99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5366 - accuracy: 0.7850\n",
      "Epoch 99/99\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5258 - accuracy: 0.7856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201c31bb088>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(\n",
    "    income_attributes_train,\n",
    "    income_target_train,\n",
    "    epochs = 99,\n",
    "    batch_size =len(income_attributes_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('aif360')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a5cc2927ccf0dec671acad1788f73f379b63ab0f4b64b4fbb2594cf7c0cd06e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
